{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J06ejXnc9Mj7",
        "outputId": "994642e8-474b-4c19-e159-836a98183312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z6g0TLML9Mj-"
      },
      "outputs": [],
      "source": [
        "class My_CBOW(nn.Module):\n",
        "    def __init__(self, vob_size:int, embed_dim:int):\n",
        "        super(My_CBOW,self).__init__()\n",
        "        self.inEmbedding = nn.Embedding(vob_size,embed_dim)\n",
        "        self.outEmbedding = nn.Embedding(vob_size,embed_dim)\n",
        "\n",
        "    #    self.h = None\n",
        "        \n",
        "    \n",
        "    def makeH(self,input):\n",
        "        W = self.inEmbedding(input)\n",
        "        n = W.shape[-2]\n",
        "\n",
        "        h = torch.sum(W,dim=-2) / n\n",
        "        return h\n",
        "\n",
        "    def forwardWithH(self,h,out):\n",
        "        W = self.outEmbedding(out)\n",
        "        score = torch.sum(h * W,dim = -1)\n",
        "        return score\n",
        "\n",
        "\n",
        "\n",
        "# ## 模型测试\n",
        "\n",
        "# cbow = My_CBOW(10,3)\n",
        "# cbow.to(device=device)\n",
        "# input = torch.Tensor([[1,2,5],[1,2,3],[6,2,3],[6,2,3]]).to(dtype=torch.int32,device = device)\n",
        "\n",
        "# ##正样本\n",
        "# h = cbow.makeH(input)\n",
        "# pout = Tensor([1,3,2,5]).to(device=device,dtype=int)\n",
        "# plable = torch.ones(pout.shape)\n",
        "# pscore = cbow.forwardWithH(h,pout)\n",
        "\n",
        "\n",
        "# ##负样本\n",
        "# nout = Tensor([1,0,1,7]).to(device=device,dtype=int)\n",
        "# nlable = torch.zeros_like(nout)\n",
        "# nsocre = cbow.forwardWithH(h,nout)\n",
        "\n",
        "\n",
        "# score = torch.cat((pscore,nsocre))\n",
        "# lables = torch.cat((plable,nlable))\n",
        "\n",
        "# print(score)\n",
        "\n",
        "\n",
        "\n",
        "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "# loss = loss_fn(score,lables)\n",
        "\n",
        "# print(loss)\n",
        "\n",
        "# loss.backward()\n",
        "\n",
        "# # input = Tensor([[1,2,5],[1,2,3],[6,2,3]],dtype=torch.int)\n",
        "# # print(input)\n",
        "\n",
        "# # cbow.makeH(input)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE5bPBNm9MkA",
        "outputId": "20f8d14c-a172-4e98-b8a2-89bf2310513b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    1    2 ...    8    9   10]\n",
            " [   1    2    3 ...    9   10   11]\n",
            " [   2    3    4 ...   10   11   12]\n",
            " ...\n",
            " [ 706 9999  119 ...  258   64   39]\n",
            " [9999  119 1143 ...   64   39   26]\n",
            " [ 119 1143   69 ...   39   26   24]]\n",
            "[   5    6    7 ...  552  917 3196]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"/content/drive/MyDrive/ml/nlp/\")\n",
        "\n",
        "import numpy\n",
        "import pickle\n",
        "\n",
        "\n",
        "from common.util import create_contexts_target\n",
        "from dataset import ptb\n",
        "\n",
        "\n",
        "window_size = 5\n",
        "hidden_size =  100\n",
        "\n",
        "batch_size = 100\n",
        "max_epoch = 10\n",
        "\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data(\"train\")\n",
        "vocab_size = len(word_to_id)\n",
        "\n",
        "context , target = create_contexts_target(corpus=corpus,window_size=window_size)\n",
        "\n",
        "print(context)\n",
        "print(target)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgsEuHmq9wh9",
        "outputId": "80f2de66-d8ea-4470-cbf4-c698733ba83a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lmt_70lr9MkB"
      },
      "outputs": [],
      "source": [
        "def train(model:My_CBOW, loss_fn , optimizer:torch.optim.Optimizer ,context : Tensor, target: Tensor, negativeTarget: Tensor):\n",
        "    # model.train()\n",
        "    h = model.makeH(context)\n",
        "\n",
        "    p_lable = torch.ones_like(target).to(device=device)\n",
        "    \n",
        "\n",
        "    p_score = model.forwardWithH(h,target).to(device=device)\n",
        "\n",
        "    n_lable = torch.zeros_like(negativeTarget).to(device=device)\n",
        "    n_score = model.forwardWithH(h,negativeTarget).to(device=device)\n",
        "\n",
        "    score = torch.cat((p_score,n_score)).to(dtype=torch.float32,device=device)\n",
        "    lables = torch.cat((p_lable,n_lable)).to(dtype=torch.float32,device=device)\n",
        "\n",
        "    loss = loss_fn(score,lables)\n",
        "    loss.backward()\n",
        "    optimizer.zero_grad()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VfaOhb4L9MkC"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "GPU = device == \"cuda\"\n",
        "class UnigramSampler:\n",
        "    def __init__(self, corpus, power, sample_size):\n",
        "        self.sample_size = sample_size\n",
        "        self.vocab_size = None\n",
        "        self.word_p = None\n",
        "\n",
        "        counts = collections.Counter()\n",
        "        for word_id in corpus:\n",
        "            counts[word_id] += 1\n",
        "\n",
        "        vocab_size = len(counts)\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.word_p = np.zeros(vocab_size)\n",
        "        for i in range(vocab_size):\n",
        "            self.word_p[i] = counts[i]\n",
        "\n",
        "        self.word_p = np.power(self.word_p, power)\n",
        "        self.word_p /= np.sum(self.word_p)\n",
        "    def get_negative_sample(self, target):\n",
        "        batch_size = target.shape[0]\n",
        "\n",
        "        if not GPU:\n",
        "            negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                p = self.word_p.copy()\n",
        "                target_idx = target[i]\n",
        "                p[target_idx] = 0\n",
        "                p /= p.sum()\n",
        "                negative_sample[i, :] = np.random.choice(self.vocab_size, size=self.sample_size, replace=False, p=p)\n",
        "        else:\n",
        "            # 在用GPU(cupy）计算时，优先速度\n",
        "            # 有时目标词存在于负例中\n",
        "            negative_sample = np.random.choice(self.vocab_size, size=(batch_size, self.sample_size),\n",
        "                                               replace=True, p=self.word_p)\n",
        "\n",
        "        return negative_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7LwkUHXn9MkC"
      },
      "outputs": [],
      "source": [
        "train_context = torch.tensor(context).to(device=device)\n",
        "train_target = torch.tensor(target).to(device = device)\n",
        "\n",
        "# print(train_context.shape)\n",
        "# print(train_target.shape)\n",
        "\n",
        "# model = My_CBOW(vocab_size,hidden_size)\n",
        "# optimizer = torch.optim.Adam(model.parameters())\n",
        "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ## 取十条负样本\n",
        "# #sampler = torch.utils.data.Sampler(data_source)\n",
        "\n",
        "# smapler = UnigramSampler(corpus,0.75,1)\n",
        "\n",
        "\n",
        "# print(target.shape)\n",
        "\n",
        "\n",
        "# batch_context = train_context[:10]\n",
        "# batch_target = train_target[:10]\n",
        "\n",
        "\n",
        "\n",
        "# negative = smapler.get_negative_sample(batch_target)\n",
        "# print(negative.shape)\n",
        "\n",
        "# negative = torch.from_numpy(negative).squeeze(dim=1)\n",
        "# ##model.train()\n",
        "\n",
        "# print(f\"batch_target_shape{batch_target.shape}\")\n",
        "# train(model,loss_fn,optimizer,batch_context,batch_target,negative)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYDnU9Dr9MkD",
        "outputId": "d630a59e-8f44-4f92-ff1f-28a3908f060e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9295\n",
            "0 / 10 : losss is 1.5197619199752808\n",
            "1 / 10 : losss is 1.4933115243911743\n",
            "2 / 10 : losss is 1.3742077350616455\n",
            "3 / 10 : losss is 1.443870186805725\n",
            "4 / 10 : losss is 1.3027026653289795\n",
            "5 / 10 : losss is 1.5266680717468262\n",
            "6 / 10 : losss is 1.6435636281967163\n",
            "7 / 10 : losss is 1.4655804634094238\n",
            "8 / 10 : losss is 1.6358784437179565\n",
            "9 / 10 : losss is 1.4294499158859253\n"
          ]
        }
      ],
      "source": [
        " \n",
        " \n",
        "smapler = UnigramSampler(corpus,0.75,1)\n",
        "loop = train_target.shape[0] // batch_size\n",
        "\n",
        "\n",
        "print(loop)\n",
        "\n",
        "\n",
        "model = My_CBOW(vocab_size,hidden_size)\n",
        "model = model.to(device=device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "loss = None\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for i in range(loop):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "\n",
        "        b_context = train_context[start : end]\n",
        "        b_target =  train_target[start : end]\n",
        "        negative = smapler.get_negative_sample(b_target)\n",
        "        negative = torch.from_numpy(negative).squeeze(dim=1).to(device= device)\n",
        "\n",
        "        model.train()\n",
        "        loss = train(model,loss_fn,optimizer,b_context,b_target,negative)\n",
        "\n",
        "    print(f\"{epoch} / {max_epoch} : losss is {loss}\")\n",
        "\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from common.util import most_similar\n",
        "\n",
        "\n",
        "## CBOW 模型的评价\n",
        "\n",
        "print(model.inEmbedding.weight.shape)\n",
        "\n",
        "\n",
        "word_vecs = model.inEmbedding.weight.detach().to(device = \"cpu\").numpy()\n",
        "\n",
        "querys = ['you','year','car','toyota']\n",
        "\n",
        "for query in querys:\n",
        "  most_similar(query,word_to_id,id_to_word,word_vecs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-TqMSjmFH39",
        "outputId": "c7fa0f97-0172-40f1-d2cd-66e8edd80d55"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 100])\n",
            "\n",
            "[query] you\n",
            " clues: 0.3754046857357025\n",
            " number: 0.34034666419029236\n",
            " am: 0.3396323025226593\n",
            " lipper: 0.33467087149620056\n",
            " disclosure: 0.32848480343818665\n",
            "\n",
            "[query] year\n",
            " exploring: 0.35146403312683105\n",
            " ortiz: 0.34905633330345154\n",
            " monitors: 0.3476950526237488\n",
            " disrupted: 0.33855801820755005\n",
            " writing: 0.32244551181793213\n",
            "\n",
            "[query] car\n",
            " adversary: 0.37265142798423767\n",
            " undeveloped: 0.34404247999191284\n",
            " midwestern: 0.32540544867515564\n",
            " realities: 0.3242040276527405\n",
            " verge: 0.31838104128837585\n",
            "\n",
            "[query] toyota\n",
            " independence: 0.4084080755710602\n",
            " shot: 0.3998439610004425\n",
            " mushrooms: 0.38378170132637024\n",
            " haven: 0.33293184638023376\n",
            " trend: 0.3326318860054016\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "fe85713bd73e29e553e0fe93aab7a5c1beebd30dbde9209efd93f425af696249"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('language')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "CBOW-improve.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}