{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J06ejXnc9Mj7",
        "outputId": "5843e235-28f3-43e9-baa7-6d04a59fb68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XHAcMhelkZgV",
        "outputId": "247e5847-23e7-410e-df09-18fcaae4f5f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z6g0TLML9Mj-"
      },
      "outputs": [],
      "source": [
        "class My_CBOW(nn.Module):\n",
        "    def __init__(self, vob_size:int, embed_dim:int, window_size:int):\n",
        "        super(My_CBOW,self).__init__()\n",
        "        self.inEmbedding = nn.Embedding(vob_size,embed_dim)\n",
        "      \n",
        "        size = embed_dim * window_size * 2;\n",
        "\n",
        "#        print(f\"size =={size}\")\n",
        "        # self.linear1 = nn.Linear(size, embed_dim)\n",
        "\n",
        "        self.outEmbedding = nn.Embedding(vob_size,embed_dim)\n",
        "\n",
        "    #    self.h = None\n",
        "        \n",
        "    \n",
        "    def makeH(self,input):\n",
        "        W = self.inEmbedding(input)\n",
        "        n = W.shape[-2]\n",
        "\n",
        "\n",
        "  #      print(f\"W.shape = {W.shape}\")\n",
        "        h = torch.sum(W,dim=-2) / n\n",
        "    #     x = W.view(input.shape[0],-1)\n",
        "\n",
        "\n",
        "    #  #   print(f\"x.shape = {x.shape}\")\n",
        "    #     h = self.linear1(x)\n",
        "    #     h = nn.functional.relu(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def forwardWithH(self,h,out):\n",
        "        W = self.outEmbedding(out)\n",
        "        score = torch.sum(h * W,dim = -1)\n",
        "        return score\n",
        "\n",
        "\n",
        "\n",
        "# ## 模型测试\n",
        "# cbow = My_CBOW(10,3,3)\n",
        "# cbow.to(device=device)\n",
        "# input = torch.Tensor([[1,2,5],[1,2,3],[6,2,3],[6,2,3]]).to(dtype=torch.int32,device = device)\n",
        "\n",
        "# ##正样本\n",
        "# h = cbow.makeH(input)\n",
        "\n",
        "# print(f\"shape{h.shape}\")\n",
        "# pout = Tensor([1,3,2,5]).to(device=device,dtype=int)\n",
        "# plable = torch.ones(pout.shape).to(device = device)\n",
        "# pscore = cbow.forwardWithH(h,pout).to(device = device)\n",
        "\n",
        "\n",
        "# ##负样本\n",
        "# nout = Tensor([1,0,1,7]).to(device=device,dtype=int)\n",
        "# nlable = torch.zeros_like(nout).to(device = device)\n",
        "# nsocre = cbow.forwardWithH(h,nout).to(device = device)\n",
        "\n",
        "\n",
        "# score = torch.cat((pscore,nsocre))\n",
        "# lables = torch.cat((plable,nlable)).to(device = device)\n",
        "# print(score)\n",
        "\n",
        "\n",
        "\n",
        "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "# loss = loss_fn(score,lables)\n",
        "\n",
        "# print(loss)\n",
        "\n",
        "# loss.backward()\n",
        "\n",
        "# input = Tensor([[1,2,5],[1,2,3],[6,2,3]],dtype=torch.int)\n",
        "# print(input)\n",
        "\n",
        "# cbow.makeH(input)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE5bPBNm9MkA",
        "outputId": "bbd2435d-a8a2-4c76-8ae6-97e18265a2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(929579, 10)\n",
            "[   5    6    7 ...  552  917 3196]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"/content/drive/MyDrive/ml/nlp/\")\n",
        "\n",
        "import numpy\n",
        "import pickle\n",
        "\n",
        "\n",
        "from common.util import create_contexts_target\n",
        "from dataset import ptb\n",
        "\n",
        "\n",
        "window_size = 5\n",
        "hidden_size =  100\n",
        "\n",
        "batch_size = 100\n",
        "max_epoch = 10\n",
        "\n",
        "\n",
        "corpus, word_to_id, id_to_word = ptb.load_data(\"train\")\n",
        "vocab_size = len(word_to_id)\n",
        "\n",
        "context , target = create_contexts_target(corpus=corpus,window_size=window_size)\n",
        "\n",
        "print(context.shape)\n",
        "print(target)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VfaOhb4L9MkC"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "GPU = device == \"cuda\"\n",
        "class UnigramSampler:\n",
        "    def __init__(self, corpus, power, sample_size):\n",
        "        self.sample_size = sample_size\n",
        "        self.vocab_size = None\n",
        "        self.word_p = None\n",
        "\n",
        "        counts = collections.Counter()\n",
        "        for word_id in corpus:\n",
        "            counts[word_id] += 1\n",
        "\n",
        "        vocab_size = len(counts)\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.word_p = np.zeros(vocab_size)\n",
        "        for i in range(vocab_size):\n",
        "            self.word_p[i] = counts[i]\n",
        "\n",
        "        self.word_p = np.power(self.word_p, power)\n",
        "        self.word_p /= np.sum(self.word_p)\n",
        "    def get_negative_sample(self, target):\n",
        "        batch_size = target.shape[0]\n",
        "\n",
        "        if not GPU:\n",
        "            negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                p = self.word_p.copy()\n",
        "                target_idx = target[i]\n",
        "                p[target_idx] = 0\n",
        "                p /= p.sum()\n",
        "                negative_sample[i, :] = np.random.choice(self.vocab_size, size=self.sample_size, replace=False, p=p)\n",
        "        else:\n",
        "            # 在用GPU(cupy）计算时，优先速度\n",
        "            # 有时目标词存在于负例中\n",
        "            negative_sample = np.random.choice(self.vocab_size, size=(batch_size, self.sample_size),\n",
        "                                               replace=True, p=self.word_p)\n",
        "\n",
        "        return negative_sample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model:My_CBOW, loss_fn , optimizer:torch.optim.Optimizer ,context : Tensor, target: Tensor, negativeTarget: Tensor):\n",
        "\n",
        "  \n",
        "    # model.train()\n",
        "    h = model.makeH(context)\n",
        "\n",
        "    p_lable = torch.ones_like(target)\n",
        "    \n",
        "\n",
        "    p_score = model.forwardWithH(h,target)\n",
        "\n",
        "    n_lable = torch.zeros_like(negativeTarget)\n",
        "    n_score = model.forwardWithH(h,negativeTarget)\n",
        "\n",
        "    score = torch.cat((p_score,n_score)).to(dtype=torch.float32)\n",
        "    lables = torch.cat((p_lable,n_lable)).to(dtype=torch.float32)\n",
        "    loss = loss_fn(score,lables)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    #optimizer.zero_grad()\n",
        "    optimizer.step()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "aYTHkWrwsx-t"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7LwkUHXn9MkC"
      },
      "outputs": [],
      "source": [
        "train_context = torch.tensor(context).to(device=device)\n",
        "train_target = torch.tensor(target).to(device = device)\n",
        "\n",
        "# print(train_context.shape)\n",
        "# print(train_target.shape)\n",
        "\n",
        "# model = My_CBOW(vocab_size,hidden_size)\n",
        "# optimizer = torch.optim.Adam(model.parameters())\n",
        "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ## 取十条负样本\n",
        "# #sampler = torch.utils.data.Sampler(data_source)\n",
        "\n",
        "# smapler = UnigramSampler(corpus,0.75,1)\n",
        "\n",
        "\n",
        "# print(target.shape)\n",
        "\n",
        "\n",
        "# batch_context = train_context[:10]\n",
        "# batch_target = train_target[:10]\n",
        "\n",
        "\n",
        "\n",
        "# negative = smapler.get_negative_sample(batch_target)\n",
        "# print(negative.shape)\n",
        "\n",
        "# negative = torch.from_numpy(negative).squeeze(dim=1)\n",
        "# ##model.train()\n",
        "\n",
        "# print(f\"batch_target_shape{batch_target.shape}\")\n",
        "# train(model,loss_fn,optimizer,batch_context,batch_target,negative)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IYDnU9Dr9MkD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = My_CBOW(vocab_size,hidden_size , window_size=window_size)\n",
        "model = model.to(device=device)\n",
        "\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "smapler = UnigramSampler(corpus,0.75,5)\n",
        "\n",
        "\n",
        "loss = 0.0\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
        "\n",
        "model.train()"
      ],
      "metadata": {
        "id": "D_xTA3CTS_qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59f593f-3883-4a58-d14b-43d0a57c0a7b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "My_CBOW(\n",
              "  (inEmbedding): Embedding(10000, 100)\n",
              "  (outEmbedding): Embedding(10000, 100)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500\n",
        "loop = train_target.shape[0] // batch_size\n",
        "\n",
        "\n",
        "print(f\"model weight : {model.inEmbedding.weight}\")\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss = 0.0\n",
        "    for i in range(loop):\n",
        "        start = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "\n",
        "        b_context = train_context[start : end]\n",
        "        b_target =  train_target[start : end]\n",
        "\n",
        "        negative = smapler.get_negative_sample(b_target)\n",
        "\n",
        "        negatives = torch.from_numpy(negative.T).to(device= device)\n",
        "\n",
        "        for j in range(5):\n",
        "          negative = negatives[j]\n",
        "          loss += train(model,loss_fn,optimizer,b_context,b_target,negative)\n",
        "\n",
        "\n",
        "        # negative = smapler.get_negative_sample(b_target)\n",
        "        # negative = torch.from_numpy(negative).squeeze(dim=1).to(device= device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "        # loss += train(model,loss_fn,optimizer,b_context,b_target,negative)\n",
        "\n",
        "    print(f\"{epoch} / {max_epoch} : losss is {loss/batch_size}\")\n",
        "\n",
        "print(f\"model weight : {model.inEmbedding.weight}\")"
      ],
      "metadata": {
        "id": "V6HLiu93zK0w",
        "outputId": "a67e8487-aaa9-4dbb-a24d-91d0038d2d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model weight : Parameter containing:\n",
            "tensor([[ 0.7684,  0.4216,  0.0579,  ...,  0.7694,  1.4998,  0.4847],\n",
            "        [-0.8013,  0.1884, -0.5305,  ...,  0.5169,  1.2377, -0.3272],\n",
            "        [ 0.9748,  0.0078,  1.1083,  ..., -0.9189,  0.3697, -1.7594],\n",
            "        ...,\n",
            "        [-0.2633,  1.3464, -0.3807,  ...,  1.7667,  0.1280, -0.5376],\n",
            "        [ 3.3827,  1.3655, -0.1167,  ..., -0.2156, -1.5520, -0.0815],\n",
            "        [-0.3408, -0.9149,  1.3900,  ...,  0.6726, -0.0064,  0.1280]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "0 / 10 : losss is 12.01616382598877\n",
            "1 / 10 : losss is 8.862168312072754\n",
            "2 / 10 : losss is 7.893669128417969\n",
            "3 / 10 : losss is 7.434049129486084\n",
            "4 / 10 : losss is 7.17485237121582\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-07f8c9dd6637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmapler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_negative_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mnegatives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 保存模型\n"
      ],
      "metadata": {
        "id": "O-rcFUqORX-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"/content/drive/MyDrive/ml/nlp/cbow-ptb.pth\")"
      ],
      "metadata": {
        "id": "1p6dN28lSAEe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 加载模型\n"
      ],
      "metadata": {
        "id": "QShqL1vwSBF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/ml/nlp/cbow-ptb.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW57ACs-SE-p",
        "outputId": "5adbab33-9089-46d0-f3d6-a2b554381aa3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from common.util import most_similar\n",
        "\n",
        "\n",
        "## CBOW 模型的评价\n",
        "\n",
        "print(model.inEmbedding.weight.shape)\n",
        "\n",
        "\n",
        "word_vecs = model.inEmbedding.weight.detach().to(device = \"cpu\").numpy()\n",
        "\n",
        "querys = ['you','year','car','toyota']\n",
        "\n",
        "for query in querys:\n",
        "  most_similar(query,word_to_id,id_to_word,word_vecs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-TqMSjmFH39",
        "outputId": "09b8d302-a658-409e-fd0d-0a3b260e4f7f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 100])\n",
            "\n",
            "[query] you\n",
            " i: 0.6182621717453003\n",
            " they: 0.607410728931427\n",
            " we: 0.5694349408149719\n",
            " nervously: 0.3941842317581177\n",
            " mom: 0.37667644023895264\n",
            "\n",
            "[query] year\n",
            " week: 0.7344915270805359\n",
            " month: 0.7199020385742188\n",
            " summer: 0.6118643879890442\n",
            " spring: 0.5503232479095459\n",
            " decade: 0.48749762773513794\n",
            "\n",
            "[query] car\n",
            " integrated: 0.3963068127632141\n",
            " cars: 0.3956888020038605\n",
            " dominated: 0.393172949552536\n",
            " chevy: 0.38974159955978394\n",
            " bid: 0.3842407166957855\n",
            "\n",
            "[query] toyota\n",
            " cars: 0.4866105616092682\n",
            " goods: 0.42563217878341675\n",
            " chrysler: 0.4079570472240448\n",
            " beers: 0.39074578881263733\n",
            " afloat: 0.3547462821006775\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "fe85713bd73e29e553e0fe93aab7a5c1beebd30dbde9209efd93f425af696249"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('language')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "CBOW-improve.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}