{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "099e593e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1523.3393860714248\n",
      "1099 43.06757716074328\n",
      "Result : y = 0.03188831451340203 +0.838950623852515x + -0.005501264877405754x^2 + -0.09079988527496523x^3\n"
     ]
    }
   ],
   "source": [
    "## wam-up : numpy\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "x = np.linspace(-math.pi,math.pi,2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate=1e-6\n",
    "\n",
    "for t in range(2000):\n",
    "    y_pred = a + b * x + c* x**2 + d * x **3\n",
    "    \n",
    "    loss = np.square(y_pred -y).sum()\n",
    "    if t % 1000 == 99:\n",
    "        print(t,loss)\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred -y)\n",
    "    \n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "    \n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "    \n",
    "print(f'Result : y = {a} +{b}x + {c}x^2 + {d}x^3')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b056177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1603.780029296875\n",
      "199 1120.01123046875\n",
      "299 783.5952758789062\n",
      "399 549.4459228515625\n",
      "499 386.3392639160156\n",
      "599 272.62884521484375\n",
      "699 193.2938232421875\n",
      "799 137.90090942382812\n",
      "899 99.1971664428711\n",
      "999 72.13575744628906\n",
      "1099 53.20216369628906\n",
      "1199 39.94694900512695\n",
      "1299 30.661449432373047\n",
      "1399 24.153162002563477\n",
      "1499 19.588932037353516\n",
      "1599 16.38643455505371\n",
      "1699 14.13825511932373\n",
      "1799 12.559293746948242\n",
      "1899 11.449851036071777\n",
      "1999 10.669976234436035\n",
      "Result : y = -0.04373520240187645 +0.8450115323066711x + 0.007545048836618662x^2 + -0.09166199713945389x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "x = torch.linspace(-math.pi,math.pi,2000, device = device,dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learngin_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    \n",
    "    if t % 100 == 99:\n",
    "        print(t,loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        a -= learngin_rate * a.grad\n",
    "        b -= learngin_rate * b.grad\n",
    "        c -= learngin_rate * c.grad\n",
    "        d -= learngin_rate * d.grad\n",
    "        \n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "        \n",
    "print(f'Result : y = {a.item()} +{b.item()}x + {c.item()}x^2 + {d.item()}x^3')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2062c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2786.662109375\n",
      "5 1233.6942138671875\n",
      "5 549.270263671875\n",
      "5 433.5107727050781\n",
      "5 408.83343505859375\n",
      "5 401.8392333984375\n",
      "5 398.5426940917969\n",
      "5 396.7341613769531\n",
      "5 395.65118408203125\n",
      "5 394.95465087890625\n",
      "5 394.4811096191406\n",
      "5 394.1449890136719\n",
      "5 393.8981018066406\n",
      "5 393.71160888671875\n",
      "5 393.5674743652344\n",
      "5 393.4538879394531\n",
      "5 393.36273193359375\n",
      "5 393.28863525390625\n",
      "5 393.2276611328125\n",
      "5 393.17681884765625\n",
      "Result : y = 0.2005510926246643 +0.24137042462825775x + 0.7049540877342224x^2 + 0.0237678624689579x^3\n"
     ]
    }
   ],
   "source": [
    "## define new autograd funtions\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class LegendrePolynomial3(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx,input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return 0.5 * (5 * input ** 3 - 3 ** input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_output):\n",
    "        input , = ctx.saved_tensors\n",
    "        return grad_output * 1.5 * (5 * input **2 -1)\n",
    "    \n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device)\n",
    "\n",
    "a = torch.full((),0.0,device=device,dtype=dtype,requires_grad=True)\n",
    "b = torch.full((),-1.0,device=device,dtype=dtype,requires_grad=True)\n",
    "c = torch.full((),0.0,device=device,dtype=dtype,requires_grad=True)\n",
    "d = torch.full((),0.3,device=device,dtype=dtype,requires_grad=True)\n",
    "\n",
    "\n",
    "learning_rate=5e-6\n",
    "\n",
    "for t in range(2000):\n",
    "    P3 = LegendrePolynomial3.apply\n",
    "    y_pred = a + b * x + P3(c + d * x)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    \n",
    "    if  t % 100 == 99:\n",
    "        print(5,loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        a -= learngin_rate * a.grad\n",
    "        b -= learngin_rate * b.grad\n",
    "        c -= learngin_rate * c.grad\n",
    "        d -= learngin_rate * d.grad\n",
    "\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "print(f'Result : y = {a.item()} +{b.item()}x + {c.item()}x^2 + {d.item()}x^3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ecf0bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000])\n",
      "99 3909.035400390625\n",
      "199 673.7952880859375\n",
      "299 113.43264770507812\n",
      "399 71.30746459960938\n",
      "499 62.864501953125\n",
      "599 51.9769172668457\n",
      "699 38.986480712890625\n",
      "799 26.127914428710938\n",
      "899 16.257158279418945\n",
      "999 10.871615409851074\n",
      "1099 9.153132438659668\n",
      "1199 8.835882186889648\n",
      "1299 8.846351623535156\n",
      "1399 8.842153549194336\n",
      "1499 9.085731506347656\n",
      "1599 9.027626991271973\n",
      "1699 9.006871223449707\n",
      "1799 8.90821647644043\n",
      "1899 8.895101547241211\n",
      "1999 8.920973777770996\n",
      "Resut: y = 0.0004930508439429104 + 0.8562325835227966x + 0.0004930515424348414x^2 + -0.09383887052536011x^3\n"
     ]
    }
   ],
   "source": [
    "##nn module\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "x = torch.linspace(-math.pi,math.pi,2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "p = torch.tensor([1,2,3])\n",
    "print(x.shape)\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(3,1),\n",
    "        torch.nn.Flatten(0,1)\n",
    "    )\n",
    "\n",
    "\n",
    "## Mean squared error \n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate=1e-3\n",
    "optimizer=torch.optim.RMSprop(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for t in range(2000):\n",
    "    y_pred = model(xx)\n",
    "    \n",
    "    loss = loss_fn(y_pred,y)\n",
    "    \n",
    "    if t % 100 == 99:\n",
    "        print(t,loss.item())\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "linear_layer = model[0]\n",
    "\n",
    "print(f'Resut: y = {linear_layer.bias.item()} + {linear_layer.weight[:,0].item()}x + {linear_layer.weight[:,1].item()}x^2 + {linear_layer.weight[:,2].item()}x^3')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom nn Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8de8ebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2029.6297607421875\n",
      "199 1402.4046630859375\n",
      "299 970.8934936523438\n",
      "399 673.6972045898438\n",
      "499 468.7836608886719\n",
      "599 327.3459167480469\n",
      "699 229.61740112304688\n",
      "799 162.02044677734375\n",
      "899 115.21717071533203\n",
      "999 82.77919006347656\n",
      "1099 60.2757568359375\n",
      "1199 44.64950180053711\n",
      "1299 33.78886795043945\n",
      "1399 26.233795166015625\n",
      "1499 20.97368049621582\n",
      "1599 17.30840492248535\n",
      "1699 14.75238037109375\n",
      "1799 12.968560218811035\n",
      "1899 11.722719192504883\n",
      "1999 10.851997375488281\n",
      "Result: -0.04404335469007492 0.8398067355155945 0.007598210126161575 -0.09092166274785995 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class Polynomial3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "    \n",
    "    def string(self):\n",
    "        return f'{self.a.item()} {self.b.item()} {self.c.item()} {self.d.item()} '\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "x = torch.linspace(-math.pi,math.pi,2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "\n",
    "\n",
    "model = Polynomial3()\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-6)\n",
    "\n",
    "\n",
    "for t in range(2000):\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = criterion(y_pred,y)\n",
    "    \n",
    "    if t % 100 == 99:\n",
    "        print(t,loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57ec104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10.0439, 10.0121,  9.9803], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.nn.Linear(3,1)\n",
    "xx[:3]\n",
    "ll = l.forward(xx[:3])\n",
    "print(ll.shape)\n",
    "\n",
    "\n",
    "f = torch.nn.Flatten(0,1)\n",
    "\n",
    "f.forward(ll)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
